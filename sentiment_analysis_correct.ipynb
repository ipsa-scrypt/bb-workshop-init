{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Welcome !\n",
    "\n",
    "> Let's see what we can do together. Let's take a look at some sentiment analysis.\n",
    "\n",
    "***To detect good sentences from bad we will use some TF-IDF matrices: Term-frequency - Inverse-Document-Frequency***\n",
    "\n",
    "![mario](https://img.freepik.com/vecteurs-libre/fond-jeu-video-dessine-main_23-2150320542.jpg)\n",
    "\n",
    "### What is it?\n",
    "Let's say we have for example: **\"I love this cat\"** and **\"I love this dog\"**, **\"I hate the movie\"**\n",
    "In this case, we can see that the frequency of love over the first sentence is 1, over the second 1 and finally 0. \n",
    "The global frequency is 2.\n",
    "Let's take a look at: \"I\", the frequency over all sentences is respectively 1. \n",
    "The global fequency of I over the document (3 sentences) is 3.\n",
    "\n",
    "### Does it mean \"I\" is more important than \"love\"?\n",
    "Nop, you're right, \"I\" is not more important. To focus on correctness of the frequency over all documents, we have to multiply the TF (term fequency) with the IDF (inverse-document-frequency):\n",
    "\n",
    "***TF * log(N/df)***\n",
    "\n",
    "N = 3 (because 3 sentences)\n",
    "* For \"I\":\n",
    "TF = 1 for the first sentence\n",
    "df = 3 because \"I\" appears in all 3 documents\n",
    "\n",
    "**TF-IDF(\"I\") = 0**, therefore, \"I\" in the first document is not a valuable information.\n",
    "\n",
    "* For \"love\":\n",
    "TF = 1 for the first sentence\n",
    "df = 2 because \"love\" appears in 2 / 3 documents\n",
    "\n",
    "**TF-IDF(\"love\")** = 0.17, therefore \"love\" is a little valuable in the first sentence.\n",
    "\n",
    "***PS: this approach will be quite wrong as it will not take into account any context.***\n",
    "\n",
    "\n",
    "| When you see a MARIO STAR, it means it's your time to shine and to code!\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21b92757c2eebd12"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.635413300Z",
     "start_time": "2023-11-26T16:57:56.730506400Z"
    }
   },
   "id": "cff87a02659db489"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Below is some bad and good \n",
    "\n",
    "We will use those sentences to create two TF-IDF matrices: one good, one bad. \n",
    "Later, we will compare every sentence we want with the two matrices and check which of the two has the closest cosine similarity (distance) in terms of TF-IDF value with the sentence we want to predict the sentiment.\n",
    "If you don't understand yet, no worries keep up!"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e79f277a036e4490"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "bad_sentences = [\n",
    "    ['I', 'hate', 'this'],\n",
    "    ['I', 'don\\'t', 'like', 'it'],\n",
    "    ['I', 'hate', 'that'],\n",
    "    ['What', 'a', 'disaster'],\n",
    "    ['Not', 'good'],\n",
    "    ['It', 'is', 'bad'],\n",
    "    ['I', 'am', 'not', 'happy'],\n",
    "    ['I', 'am', 'unhappy'],\n",
    "    ['I', 'am', 'sad'],\n",
    "    ['I', 'am', 'mad'],\n",
    "    ['I', 'am', 'angry'],\n",
    "    ['I', 'am', 'not', 'glad'],\n",
    "    ['I', 'am', 'not', 'pleased'],\n",
    "    ['I', 'am', 'not', 'satisfied'],\n",
    "    ['I', 'am', 'not', 'content'],\n",
    "    ['I', 'am', 'not', 'cheerful'],\n",
    "    ['I', 'am', 'not', 'delighted'],\n",
    "    ['I', 'am', 'not', 'joyful'],\n",
    "    ['I', 'am', 'not', 'joyous'],\n",
    "    ['I', 'am', 'not', 'jubilant'],\n",
    "    ['I', 'am', 'not', 'ecstatic'],\n",
    "    ['I', 'am', 'not', 'elated'],\n",
    "    ['I', 'am', 'not', 'overjoyed'],\n",
    "    ['I', 'am', 'not', 'thrilled'],\n",
    "    ['I', 'am', 'not', 'excited'],\n",
    "    ['I', 'am', 'not', 'exhilarated'],\n",
    "    ['I', 'am', 'not', 'euphoric'],\n",
    "    ['I', 'am', 'not', 'blissful'],\n",
    "    ['I', 'am', 'not', 'cheery'],\n",
    "    ['I', 'am', 'not', 'chipper'],\n",
    "    ['I', 'am', 'not', 'contented'],\n",
    "    ['I', 'am', 'not', 'enjoying'],\n",
    "    ['I', 'am', 'not', 'glad'],\n",
    "    ['I', 'am', 'not', 'gratified'],\n",
    "    ['I', 'am', 'not', 'gratifying'],\n",
    "    ['I', 'am', 'not', 'happy'],\n",
    "    ['I', 'am', 'not', 'joyous'],\n",
    "    ['I', 'am', 'not', 'jubilant'],\n",
    "    ['I', 'am', 'not', 'pleased'],\n",
    "    ['I', 'am', 'not', 'pleasing'],\n",
    "    ['I', 'am', 'not', 'satisfied']\n",
    "]\n",
    "\n",
    "good_sentences = [\n",
    "    ['I', 'love', 'this'],\n",
    "    ['I', 'like', 'it'],\n",
    "    ['I', 'love', 'it'],\n",
    "    ['What', 'a', 'wonderful', 'day'],\n",
    "    ['Good'],\n",
    "    ['It', 'is', 'good'],\n",
    "    ['I', 'am', 'happy'],\n",
    "    ['I', 'am', 'glad'],\n",
    "    ['I', 'am', 'pleased'],\n",
    "    ['I', 'am', 'satisfied'],\n",
    "    ['I', 'am', 'content'],\n",
    "    ['I', 'am', 'cheerful'],\n",
    "    ['I', 'am', 'delighted'],\n",
    "    ['I', 'am', 'joyful'],\n",
    "    ['I', 'am', 'joyous'],\n",
    "    ['I', 'am', 'jubilant'],\n",
    "    ['I', 'am', 'ecstatic'],\n",
    "    ['I', 'am', 'elated'],\n",
    "    ['I', 'am', 'overjoyed'],\n",
    "    ['I', 'am', 'thrilled'],\n",
    "    ['I', 'am', 'excited'],\n",
    "    ['I', 'am', 'exhilarated'],\n",
    "    ['I', 'love', 'that', 'a', 'lot'],\n",
    "    ['I', 'am', 'euphoric'],\n",
    "    ['I', 'am', 'pleased'],\n",
    "    ['I', 'am', 'pleasing'],\n",
    "    ['I', 'am', 'satisfied']\n",
    "\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.649326Z",
     "start_time": "2023-11-26T16:58:21.634416Z"
    }
   },
   "id": "e7ae5c7ae41f599d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Time to code!** <img src=\"https://mario.wiki.gallery/images/thumb/f/f5/StarMK8.png/1200px-StarMK8.png\" width=\"200\"> **Time to code!**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff4ef0d80bbc7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Term Frequency\n",
    "As we said earlier, we will first calculate the term frequency of each word in each sentence.\n",
    "\n",
    "->TIPS:\n",
    "- Create an empty dictionary\n",
    "- Loop over each sentence\n",
    "- Loop over each word in the sentence\n",
    "- If the word is already in the dictionary, add 1 to the value\n",
    "- If the word is not in the dictionary, add the word as a key and set the value to 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b0b3d075f0e1aa3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.679410600Z",
     "start_time": "2023-11-26T16:58:21.652352600Z"
    }
   },
   "outputs": [],
   "source": [
    "def term_frequency(tokenized_sentences):\n",
    "    scrypt_tf = {}\n",
    "    for tokenized_sentence in tokenized_sentences:\n",
    "        for word in tokenized_sentence:\n",
    "            if word in scrypt_tf:\n",
    "                scrypt_tf[word] += 1\n",
    "            else:\n",
    "                scrypt_tf[word] = 1\n",
    "    return scrypt_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "tf_bad = term_frequency(bad_sentences)\n",
    "tf_good = term_frequency(good_sentences)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.680442900Z",
     "start_time": "2023-11-26T16:58:21.667389900Z"
    }
   },
   "id": "67c6b8b87cb1faa9"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "global_shape = len(tf_bad) + len(tf_good)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.695225500Z",
     "start_time": "2023-11-26T16:58:21.683403100Z"
    }
   },
   "id": "59dcd882e2387d7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. TF Matrix\n",
    "Now that we have the term frequency of each word, we will create a matrix with the shape of the number of sentences and the number of words in the dictionary.\n",
    "\n",
    "->TIPS:\n",
    "- Create an empty matrix (list of lists)\n",
    "- Loop over each sentence\n",
    "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
    "- Loop over each word in the sentence\n",
    "- If the word is in the dictionary, add the number of times the word appears in the sentence to the vector\n",
    "- If the word is not in the dictionary, add 0 to the vector\n",
    "- Add the vector to the matrix\n",
    "- Return the matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cf83f88f6493b8b"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def tf_matrix(tokenized_sentences, tf):\n",
    "    tf_matrix = []\n",
    "    for tokenized_sentence in tokenized_sentences:\n",
    "        tf_vector = [0]*global_shape\n",
    "        for word in tokenized_sentence:\n",
    "            if word in tf:\n",
    "                tf_vector[list(tf.keys()).index(word)] = tokenized_sentence.count(word)\n",
    "        tf_matrix.append(tf_vector)\n",
    "    print(\n",
    "        \"Shape of TF Matrix : \\n\",\n",
    "        np.array(tf_matrix).shape\n",
    "    )\n",
    "    print(\n",
    "        \"TF Matrix : \\n\",\n",
    "        np.array(tf_matrix)\n",
    "    )\n",
    "    return tf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.729471800Z",
     "start_time": "2023-11-26T16:58:21.699244100Z"
    }
   },
   "id": "b472ad32c366de3e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF Matrix : \n",
      " (41, 80)\n",
      "TF Matrix : \n",
      " [[1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n",
      "Shape of TF Matrix : \n",
      " (27, 80)\n",
      "TF Matrix : \n",
      " [[1 1 1 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 1 0 ... 0 0 0]\n",
      " ...\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]\n",
      " [1 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "tf_matrix_bad = tf_matrix(bad_sentences, tf_bad)\n",
    "tf_matrix_good = tf_matrix(good_sentences, tf_good)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.731808200Z",
     "start_time": "2023-11-26T16:58:21.714250300Z"
    }
   },
   "id": "756b6ccfe6c8b416"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. IDF Matrix\n",
    "Now that we have the TF matrix, we will create the IDF matrix.\n",
    "\n",
    "->TIPS:\n",
    "- Create an empty vector (list)\n",
    "- Loop over each word in the dictionary\n",
    "- Create a counter\n",
    "- Loop over each sentence\n",
    "- If the word is in the sentence, add 1 to the counter\n",
    "- Add the log of the number of sentences divided by the counter + 1 to the vector\n",
    "- Return the vector"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b0cc8c3af14cd5e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def idf_matrix(tf_matrix):\n",
    "    idf_matrix = []\n",
    "    for i in range(len(tf_matrix[0])):\n",
    "        count = 0\n",
    "        for j in range(len(tf_matrix)):\n",
    "            if tf_matrix[j][i] != 0:\n",
    "                count += 1\n",
    "        idf_matrix.append(np.log((len(tf_matrix)) / (count + 1)))\n",
    "    print(\n",
    "        \"Shape of IDF Matrix : \\n\",\n",
    "        np.array(idf_matrix).shape\n",
    "    )\n",
    "    print(\n",
    "        \"IDF Matrix : \\n\",\n",
    "        np.array(idf_matrix)\n",
    "    )\n",
    "    return idf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.743348Z",
     "start_time": "2023-11-26T16:58:21.727964600Z"
    }
   },
   "id": "d5e79992cc89abad"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of IDF Matrix : \n",
      " (80,)\n",
      "IDF Matrix : \n",
      " [0.05001042 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489\n",
      " 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
      " 3.02042489 3.02042489 3.02042489 0.13005313 0.24783616 2.61495978\n",
      " 3.02042489 3.02042489 3.02042489 3.02042489 2.61495978 2.61495978\n",
      " 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489 2.61495978\n",
      " 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
      " 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
      " 3.02042489 3.02042489 3.02042489 3.02042489 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
      " 3.71357207 3.71357207]\n",
      "Shape of IDF Matrix : \n",
      " (80,)\n",
      "IDF Matrix : \n",
      " [0.07696104 1.9095425  2.60268969 2.60268969 2.19722458 2.60268969\n",
      " 2.19722458 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
      " 2.60268969 0.25131443 2.60268969 2.60268969 2.19722458 2.19722458\n",
      " 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
      " 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
      " 2.60268969 2.60268969 2.60268969 2.60268969 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
      " 3.29583687 3.29583687]\n"
     ]
    }
   ],
   "source": [
    "idf_matrix_bad = idf_matrix(tf_matrix_bad)\n",
    "idf_matrix_good = idf_matrix(tf_matrix_good)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.819224400Z",
     "start_time": "2023-11-26T16:58:21.745343Z"
    }
   },
   "id": "1e544edc28877019"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4. TF-IDF Matrix\n",
    "Now that we have the TF matrix and the IDF matrix, we will create the TF-IDF matrix.\n",
    "\n",
    "->TIPS:\n",
    "- Create an empty matrix (list of lists)\n",
    "- Loop over the TF matrix\n",
    "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
    "- Loop over each word in the sentence\n",
    "- Multiply the TF value with the IDF value\n",
    "- Add the value to the vector\n",
    "- Add the vector to the matrix\n",
    "- Return the matrix"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eefe364a0cb51ad6"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def tf_idf_matrix(tf_matrix, idf_matrix):\n",
    "    tf_idf_matrix = []\n",
    "    for i in range(len(tf_matrix)):\n",
    "        tf_idf_vector = []\n",
    "        for j in range(len(tf_matrix[0])):\n",
    "            tf_idf_vector.append(tf_matrix[i][j] * idf_matrix[j])\n",
    "        tf_idf_matrix.append(tf_idf_vector)\n",
    "    print(\n",
    "        \"Shape of TF-IDF Matrix : \\n\",\n",
    "        np.array(tf_idf_matrix).shape\n",
    "    )\n",
    "    print(\n",
    "        \"TF-IDF Matrix : \\n\",\n",
    "        np.array(tf_idf_matrix)\n",
    "    )\n",
    "    return tf_idf_matrix"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.830221800Z",
     "start_time": "2023-11-26T16:58:21.762346200Z"
    }
   },
   "id": "9e3e70da8336d719"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TF-IDF Matrix : \n",
      " (41, 80)\n",
      "TF-IDF Matrix : \n",
      " [[0.05001042 2.61495978 3.02042489 ... 0.         0.         0.        ]\n",
      " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.05001042 2.61495978 0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.05001042 0.         0.         ... 0.         0.         0.        ]]\n",
      "Shape of TF-IDF Matrix : \n",
      " (27, 80)\n",
      "TF-IDF Matrix : \n",
      " [[0.07696104 1.9095425  2.60268969 ... 0.         0.         0.        ]\n",
      " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07696104 1.9095425  0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.07696104 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tf_idf_matrix_bad = tf_idf_matrix(tf_matrix_bad, idf_matrix_bad)\n",
    "tf_idf_matrix_good = tf_idf_matrix(tf_matrix_good, idf_matrix_good)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:21.831219300Z",
     "start_time": "2023-11-26T16:58:21.776874Z"
    }
   },
   "id": "5dc20545fa263033"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5. Check sentiment\n",
    "Now that we have the two TF-IDF matrices, we can check the sentiment of any sentence we want.\n",
    "To check the sentiment, we will calculate the cosine similarity between the sentence we want to check and the two TF-IDF matrices.\n",
    "The TF-IDF matrix with the highest cosine similarity will be the one with the closest distance to the sentence we want to check.\n",
    "\n",
    "For example, for the sentence \"I love this cat\", the cosine similarity with the good TF-IDF matrix could be 0.5 and the cosine similarity with the bad TF-IDF matrix could be 0.2.\n",
    "In this case, the sentence \"I love this cat\" will be considered as a good sentence.\n",
    "\n",
    "->TIPS:\n",
    "- Create a function that takes a query as an input (a sentence)\n",
    "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
    "- Combine all words from both tf_bad and tf_good as a set: **all_words = set(list(tf_bad.keys()) + list(tf_good.keys()))**\n",
    "- Loop over each word in the set\n",
    "- If the word is in the query:\n",
    "    - If the word is in tf_bad:\n",
    "        - Add the TF-IDF value to the vector with the index of the word in tf_bad as index and the idf_matrix_bad value as value\n",
    "    - If the word is in tf_good:\n",
    "        - Add the TF-IDF value to the vector with the index of the word in tf_good as index and the idf_matrix_good value as value\n",
    "- Calculate the cosine similarity between the query vector and the good TF-IDF matrix: **cosine_similarity([query_vector], tf_idf_matrix_good)[0][0]**\n",
    "- Calculate the cosine similarity between the query vector and the bad TF-IDF matrix: **cosine_similarity([query_vector], tf_idf_matrix_bad)[0][0]**\n",
    "- If the cosine similarity with the good TF-IDF matrix is higher than the cosine similarity with the bad TF-IDF matrix:\n",
    "    - Print the query with a smiley (or whatever :p)\n",
    "    - Else: print the query with a sad smiley (or whatever :p)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d8b4231f26b3c9a"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "good_query = \"WOW, I am so happy to meet you!\"\n",
    "bad_query = \"I hate it a lot!\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:51.769999600Z",
     "start_time": "2023-11-26T16:58:51.750952300Z"
    }
   },
   "id": "76d75fe7f6b9607"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def check_sentiment(query):\n",
    "    query_to_array = query.split()\n",
    "    # convert the query to a tf-idf vector\n",
    "    query_tf_idf_vector = [0]*global_shape\n",
    "    all_words = set(list(tf_bad.keys()) + list(tf_good.keys()))\n",
    "    for word in all_words:\n",
    "        if word in query_to_array:\n",
    "            if word in tf_bad:\n",
    "                query_tf_idf_vector[list(tf_bad.keys()).index(word)] = query_to_array.count(word) * idf_matrix_bad[list(tf_bad.keys()).index(word)]\n",
    "            elif word in tf_good:\n",
    "                query_tf_idf_vector[list(tf_good.keys()).index(word)] = query_to_array.count(word) * idf_matrix_good[list(tf_good.keys()).index(word)]\n",
    "\n",
    "    # calculate cosine similarity between query vector and good and bad vectors\n",
    "    cosine_similarities_with_good = cosine_similarity([query_tf_idf_vector], tf_idf_matrix_good)[0][0]\n",
    "    cosine_similarities_with_bad = cosine_similarity([query_tf_idf_vector], tf_idf_matrix_bad)[0][0]\n",
    "\n",
    "    if cosine_similarities_with_good >= cosine_similarities_with_bad:\n",
    "        print(f\"{query} => :) UwU\")\n",
    "    else:\n",
    "        print(f\"{query} => :( OoO\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:52.093158700Z",
     "start_time": "2023-11-26T16:58:52.082245Z"
    }
   },
   "id": "c1821720c45a30ed"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOW, I am so happy to meet you! => :) UwU\n",
      "I hate it a lot! => :( OoO\n"
     ]
    }
   ],
   "source": [
    "check_sentiment(good_query)\n",
    "check_sentiment(bad_query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-26T16:58:52.454701400Z",
     "start_time": "2023-11-26T16:58:52.428366800Z"
    }
   },
   "id": "3574933f09b890da"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
